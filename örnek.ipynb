{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MPnFAw6xEHx"
      },
      "source": [
        "##Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqkhzLM3nZ3p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8jr6ccFnumw"
      },
      "source": [
        "##Ä°mport Dataset and get dependent / independent values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SF4QmblMnlNC"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('insurance.csv')\n",
        "y = dataset.iloc[:,-1].values # ilk sutun son sutun\n",
        "X = dataset.iloc[:,:-1].values # ilk sutun son sutun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6aKEjSEoM2v"
      },
      "source": [
        "##Encoding Sex and Smoker columns with using LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_KxdkPboVxv"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        " \n",
        "X[:,1] = le.fit_transform(X[:,1]) #male = 0, female = 1\n",
        "X[:,4] = le.fit_transform(X[:,4]) #no = 1, yes = 0\n",
        "X[:,5] = le.fit_transform(X[:,5]) #region"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JfJwKZ7rMDw"
      },
      "source": [
        "##Split the dataset into the train set and test set (2nd Operation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZARIBOqrPpS"
      },
      "outputs": [],
      "source": [
        "def splitData(X):\n",
        "  global randomstate\n",
        "\n",
        "  # Split the dataset\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state = randomstate)\n",
        "  \n",
        "  # Feature Scaling\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  sc = StandardScaler()\n",
        "  X_train[:,:] = sc.fit_transform(X_train[:,:])\n",
        "  X_test[:,:] = sc.transform(X_test[:,:])\n",
        "  \n",
        "  return decisionTreeRegression(X_train,y_train,X_test,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gmDqMqarhBc"
      },
      "source": [
        "##Random Forest Regression (3rd Operation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sECfkoVrivM"
      },
      "outputs": [],
      "source": [
        "def randomForestRegression(X_train,y_train,X_test,y_test):\n",
        "  from sklearn.ensemble import RandomForestRegressor\n",
        "  global randomstate\n",
        "  regressor = RandomForestRegressor(n_estimators = 10,random_state=randomstate)\n",
        "  regressor.fit(X_train, y_train)\n",
        "  y_pred = regressor.predict(X_test)\n",
        "  return calculateScores(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzOMftFKfXip"
      },
      "source": [
        "##Decision Tree Regression (3rd Operation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STUBX37Dfcl6"
      },
      "outputs": [],
      "source": [
        "def decisionTreeRegression(X_train,y_train,X_test,y_test):\n",
        "  from sklearn.tree import DecisionTreeRegressor\n",
        "  global randomstate\n",
        "  regressor = DecisionTreeRegressor(random_state = randomstate)\n",
        "  regressor.fit(X_train, y_train)\n",
        "  y_pred = regressor.predict(X_test)\n",
        "  return calculateScores(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S6cSDI8gkCq"
      },
      "source": [
        "##KNN Regression (3rd Operation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEu4B69ugouE"
      },
      "outputs": [],
      "source": [
        "def knnRegression(X_train,y_train,X_test,y_test):\n",
        "  from sklearn.neighbors import KNeighborsRegressor\n",
        "  regressor = KNeighborsRegressor()\n",
        "  regressor.fit(X_train,y_train)\n",
        "  y_pred = regressor.predict(X_test)\n",
        "  return calculateScores(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-y4xUlkrk_u"
      },
      "source": [
        "##Calculate R2 Score, MAE and MSE(4th Operation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saHSpeiVrms8"
      },
      "outputs": [],
      "source": [
        "def calculateScores(y_test,y_pred):\n",
        "  \n",
        "  \n",
        "  from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
        "  \n",
        "  #r2\n",
        "  r2Score = r2_score(y_test, y_pred) \n",
        "  \n",
        "  #mae\n",
        "  mae = mean_absolute_error(y_test, y_pred) \n",
        "\n",
        "  #mse\n",
        "  mse = mean_squared_error(y_test,y_pred,squared = False)\n",
        "\n",
        "  return [r2Score,round(mae,4),round(mse,4)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLDOt0s1ruuo"
      },
      "source": [
        "##Send Features (1st Operation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OciLUqfYrvfe"
      },
      "outputs": [],
      "source": [
        "def getFeatures():\n",
        "  global indexes,X,maxR2,r2_features,minMAE,mae_features,minMSE,mse_features\n",
        "\n",
        "  # print selected values\n",
        "  print(\"Features: \",dataset.columns.values[indexes])\n",
        "\n",
        "  # get features values\n",
        "  values = X[:,indexes] \n",
        "\n",
        "  # send features values and get R2, MAE and MSE scores to the scores list. (indexes: 0 = r2, 1 = mae, 2 = mse)\n",
        "  scores = splitData(values) \n",
        "  \n",
        "  # print scores\n",
        "  print(\"R2  score: \",round(scores[0],5),\"\\nMAE score: \",scores[1],\"\\nMSE score: \",scores[2],\"\\n\")\n",
        "\n",
        "  \n",
        "  # compare current r2 score and max r2 score\n",
        "  if(scores[0]>maxR2): \n",
        "    maxR2 = scores[0]\n",
        "    r2_features.clear() # remmove the current features\n",
        "    r2_features.append(dataset.columns.values[indexes]) # add current selected features\n",
        "  \n",
        "  # if current r2 score = max r2 score \n",
        "  elif(scores[0] == maxR2):\n",
        "    r2_features.append(dataset.columns.values[indexes]) #add new features to the matrix\n",
        "\n",
        "\n",
        "  # compare current mae score and min mae score\n",
        "  if(scores[1]<minMAE):\n",
        "    minMAE = scores[1]\n",
        "    mae_features.clear()\n",
        "    mae_features.append(dataset.columns.values[indexes])\n",
        "  # if current mae score == min mae score\n",
        "  elif(scores[1] == minMAE):\n",
        "    mae_features.append(dataset.columns.values[indexes])\n",
        "\n",
        "  # compare current mse score and min mse score\n",
        "  if(scores[2]<minMSE):\n",
        "    minMSE = scores[2]\n",
        "    mse_features.clear()\n",
        "    mse_features.append(dataset.columns.values[indexes])\n",
        "\n",
        "  # if current mse score == min mse score  \n",
        "  elif(scores[2] == minMSE):\n",
        "    mse_features.append(dataset.columns.values[indexes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bovOoZhqryps"
      },
      "source": [
        "##Select Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLb9GbHJrz6Q",
        "outputId": "c7c296b1-4ebd-47cb-d0c0-b5873a571d91"
      },
      "outputs": [],
      "source": [
        "# always split and train the same random values for each loop, otherwise the algorithm will learn with different values by distinguishing differently in each loop.\n",
        "from random import randint\n",
        "randomstate = randint(0,2**32-1) # some goods: 1,245,748,328 || 2,064,061,974 || 3,546,591,408\n",
        "\n",
        "# define maximum R2 score\n",
        "maxR2 = 0\n",
        "# it takes the features where the r2 score is highest.\n",
        "r2_features = []\n",
        "\n",
        "import sys\n",
        "# define min MAE Score and MSE Score\n",
        "minMAE = sys.maxsize\n",
        "mae_features = [] # it takes the features where the mae score is lowest.\n",
        "\n",
        "minMSE = sys.maxsize\n",
        "mse_features = [] # it takes the features where the mae score is lowest.\n",
        "\n",
        "# select features  (63 rows : 6 15 20 15 6 1)\n",
        "for i in range(0,6):\n",
        "  indexes = [i]\n",
        "  getFeatures()\n",
        "  for j in range(-6+i,-1):\n",
        "    indexes = [i,j]\n",
        "    getFeatures()\n",
        "    for k in range(j+1,-1):\n",
        "      indexes = [i,j,k]\n",
        "      getFeatures()\n",
        "      for m in range(k+1,-1):\n",
        "        indexes = [i,j,k,m]\n",
        "        getFeatures()\n",
        "        for n in range(m+1,-1):\n",
        "          indexes = [i,j,k,m,n]\n",
        "          getFeatures()\n",
        "          for s in range(n+1,-1):\n",
        "            indexes = [i,j,k,m,n,s]\n",
        "            getFeatures()\n",
        "\n",
        "\n",
        "# Print Results\n",
        "print(\"\\n\")        \n",
        "print(\"Result of ?\".center(50,\"*\"))\n",
        "\n",
        "\n",
        "print(f\"\\nMax R2 Score: {round(maxR2,5)}\")\n",
        "print(\"R2 Features:\")\n",
        "for i in range(0,len(r2_features)):\n",
        "  print(r2_features[i])\n",
        "\n",
        "print(\"\".center(25,\"-\"))\n",
        "\n",
        "\n",
        "print(f\"\\nMin MAE Score: {minMAE}\")\n",
        "print(\"MAE Features:\")\n",
        "for i in range(0,len(mae_features)):\n",
        "  print(mae_features[i])\n",
        "\n",
        "print(\"\".center(25,\"-\"))\n",
        "\n",
        "\n",
        "print(f\"\\nMin MSE Score: {minMSE}\") # minMSE:,   = virgÃ¼llÃ¼ yazdÄ±rma\n",
        "print(\"MSE Features:\")\n",
        "for i in range(0,len(mse_features)):\n",
        "  print(mse_features[i])\n",
        "\n",
        "print(\"\".center(25,\"-\"))\n",
        "\n",
        "\n",
        "print(f\"\\nrandom state:  {randomstate:,}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Final Ãdev.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "84ce8ec71d70199c08d2380c9bab35960bde9e8fe30dd3071e7883d2609c9b6f"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('reg')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
